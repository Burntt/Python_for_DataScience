{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp_Atk</th>\n",
       "      <th>Sp_Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>HighStage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  #       Name Type_1  Type_2  Total  HP  Attack  Defense  \\\n",
       "0           0  1  Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1           1  2    Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2           2  3   Venusaur  Grass  Poison    525  80      82       83   \n",
       "\n",
       "   Sp_Atk  Sp_Def  Speed  Stage  Legendary  HighStage  \n",
       "0      65      65     45      1      False          0  \n",
       "1      80      80     60      2      False          1  \n",
       "2     100     100     80      3      False          1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_df = pd.read_csv('new_data_pokemon_classification.csv')\n",
    "\n",
    "pokemon_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 15)\n",
      "(105, 15)\n"
     ]
    }
   ],
   "source": [
    "train, test = model_selection.train_test_split(pokemon_df, \n",
    "                                test_size = 0.3,\n",
    "                                random_state = 2020)\n",
    "\n",
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6.1: Compute metrics for exp_1_1 -- exp_1_3 and store them in exp_1/[exp_id].report.yaml metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_1 import exp_1_1_class_version\n",
    "from exp_1 import exp_1_2_class_version\n",
    "from exp_1 import exp_1_3_class_version\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(target,pred):\n",
    "    m1 = metrics.precision_score(target,pred)\n",
    "    m2 = metrics.recall_score(target,pred)\n",
    "    m3 = metrics.accuracy_score(target,pred)\n",
    "    m4 = metrics.adjusted_mutual_info_score(target,pred)\n",
    "    return {'precision': m1, 'recall':m2, 'accuracy_score': m3, 'adjusted_mutual_info_score': m4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_1_class_instance = \\\n",
    "    exp_1_1_class_version.Exp1_1Classifier()\n",
    "\n",
    "exp_1_1_class_instance.fit(train)\n",
    "exp_1_1_test = exp_1_1_class_instance.predict(test)\n",
    "predictions['1'] = get_metrics(test['HighStage'], exp_1_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp_1_2 classifier initialized\n"
     ]
    }
   ],
   "source": [
    "exp_1_2_class_instance = \\\n",
    "    exp_1_2_class_version.Exp1_2Classifier()\n",
    "\n",
    "exp_1_2_class_instance.fit(train)\n",
    "exp_1_2_test = exp_1_2_class_instance.predict(test)\n",
    "predictions['2'] = get_metrics(test['HighStage'], exp_1_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usign configuration file exp_1/exp_1_3_configs.yaml:\n",
      "{'description': 'Features and regularization paramteres are moved to yaml file. \\nEverything else is similar to exp_1_1 and exp_1_2\\n', 'regularization': 'l2', 'features': ['HP', 'Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed'], 'polynomial_degree': 4}\n"
     ]
    }
   ],
   "source": [
    "exp_1_3_class_instance = \\\n",
    "    exp_1_3_class_version.Exp1_3Classifier('exp_1/exp_1_3_configs.yaml')\n",
    "\n",
    "exp_1_3_class_instance.fit(train)\n",
    "exp_1_3_test = exp_1_3_class_instance.predict(test)\n",
    "predictions['3'] = get_metrics(test['HighStage'], exp_1_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.75,\n",
       "  'accuracy_score': 0.6739130434782609,\n",
       "  'adjusted_mutual_info_score': 0.07304845263695448},\n",
       " '2': {'precision': 0.6896551724137931,\n",
       "  'recall': 0.8333333333333334,\n",
       "  'accuracy_score': 0.717391304347826,\n",
       "  'adjusted_mutual_info_score': 0.13042901870505733},\n",
       " '3': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.75,\n",
       "  'accuracy_score': 0.6739130434782609,\n",
       "  'adjusted_mutual_info_score': 0.07304845263695448}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.yml', 'w') as outfile:\n",
    "    yaml.dump(predictions, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6666666666666666, 'recall': 0.75, 'accuracy_score': 0.6739130434782609, 'adjusted_mutual_info_score': 0.07304845263695448}\n",
      "{'precision': 0.6896551724137931, 'recall': 0.8333333333333334, 'accuracy_score': 0.717391304347826, 'adjusted_mutual_info_score': 0.13042901870505733}\n",
      "{'precision': 0.6666666666666666, 'recall': 0.75, 'accuracy_score': 0.6739130434782609, 'adjusted_mutual_info_score': 0.07304845263695448}\n"
     ]
    }
   ],
   "source": [
    "for key, value in predictions.items():\n",
    "    with open(str(key) + '.report.yaml', 'w') as file:\n",
    "        documents = yaml.dump(value, file)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???????????????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = dict(\n",
    "    A = 'a',\n",
    "    B = dict(\n",
    "        C = 'c',\n",
    "        D = 'd',\n",
    "        E = 'e',\n",
    "    )\n",
    ")\n",
    "\n",
    "with open('data.yml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import yaml\n",
    "\n",
    "users = [{'name': 'John Doe', 'occupation': 'gardener'},\n",
    "         {'name': 'Lucy Black', 'occupation': 'teacher'}]\n",
    "\n",
    "with open('users.yaml', 'w') as f:\n",
    "    \n",
    "    data = yaml.dump(users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6.2: Add method to classifiers for predicting probabilities (predict_proba in logistic regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added predict proba to classifier 1, the rest gets it by inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.25981190e-01, 1.74018810e-01],\n",
       "       [2.07872830e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.39425798e-26],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.46229499e-01, 5.37705012e-02],\n",
       "       [7.40365734e-04, 9.99259634e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [2.97197348e-01, 7.02802652e-01],\n",
       "       [8.65385194e-02, 9.13461481e-01],\n",
       "       [1.44416657e-04, 9.99855583e-01],\n",
       "       [3.99409972e-01, 6.00590028e-01],\n",
       "       [4.79204504e-03, 9.95207955e-01],\n",
       "       [2.54358733e-01, 7.45641267e-01],\n",
       "       [7.98091566e-01, 2.01908434e-01],\n",
       "       [9.00017193e-01, 9.99828072e-02],\n",
       "       [8.60796941e-01, 1.39203059e-01],\n",
       "       [9.99985332e-01, 1.46682343e-05],\n",
       "       [1.00000000e+00, 1.59800734e-15],\n",
       "       [1.51849990e-08, 9.99999985e-01],\n",
       "       [1.00000000e+00, 7.64263299e-24],\n",
       "       [2.12098108e-06, 9.99997879e-01],\n",
       "       [9.75682301e-03, 9.90243177e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.20424806e-04, 9.99879575e-01],\n",
       "       [2.60098841e-02, 9.73990116e-01],\n",
       "       [2.81507188e-08, 9.99999972e-01],\n",
       "       [6.14674096e-01, 3.85325904e-01],\n",
       "       [7.97567359e-02, 9.20243264e-01],\n",
       "       [7.60779943e-01, 2.39220057e-01],\n",
       "       [9.99999902e-01, 9.84383790e-08],\n",
       "       [1.08276406e-06, 9.99998917e-01],\n",
       "       [9.99737538e-01, 2.62461867e-04],\n",
       "       [3.32443295e-01, 6.67556705e-01],\n",
       "       [7.31266342e-02, 9.26873366e-01],\n",
       "       [1.85225236e-08, 9.99999981e-01],\n",
       "       [1.97713040e-05, 9.99980229e-01],\n",
       "       [9.95548240e-01, 4.45176010e-03],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.74868786e-10, 1.00000000e+00],\n",
       "       [9.37827642e-01, 6.21723583e-02],\n",
       "       [1.00000000e+00, 5.86005416e-15],\n",
       "       [1.83153492e-10, 1.00000000e+00],\n",
       "       [1.22145544e-04, 9.99877854e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [8.97049913e-01, 1.02950087e-01],\n",
       "       [1.00000000e+00, 1.18539264e-11]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_1_3_class_instance.predict_proba(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6.3: compute the following metics and update yaml repor files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- roc_auc_score\n",
    "- log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(target,pred):\n",
    "    m1 = metrics.precision_score(target,pred)\n",
    "    m2 = metrics.recall_score(target,pred)\n",
    "    m3 = metrics.accuracy_score(target,pred)\n",
    "    m4 = metrics.adjusted_mutual_info_score(target,pred)\n",
    "    m5 = metrics.roc_auc_score(target,pred)\n",
    "    m6 = metrics.log_loss(target,pred)\n",
    "    return {'precision': m1, 'recall':m2, 'accuracy_score': m3, 'adjusted_mutual_info_score': m4 , 'roc_auc_score' : m5, 'log_loss' : m6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['1'] = get_metrics(test['HighStage'], exp_1_1_test)\n",
    "predictions['2'] = get_metrics(test['HighStage'], exp_1_2_test)\n",
    "predictions['3'] = get_metrics(test['HighStage'], exp_1_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Features and regularization paramteres are moved to yaml file. \\nEverything else is similar to exp_1_1 and exp_1_2\\n', 'regularization': 'l2', 'features': ['HP', 'Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed'], 'polynomial_degree': 4}\n"
     ]
    }
   ],
   "source": [
    "#load into dictionary\n",
    "\n",
    "with open('exp_1/exp_1_3_configs.yaml') as f:\n",
    "    configs = yaml.load(f, Loader=yaml.Loader)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite  yaml file ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
